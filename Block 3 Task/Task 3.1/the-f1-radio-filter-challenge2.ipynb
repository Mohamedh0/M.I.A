{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111472,"databundleVersionId":13267583,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Important Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:28.022356Z","iopub.execute_input":"2025-08-09T07:05:28.022668Z","iopub.status.idle":"2025-08-09T07:05:29.138257Z","shell.execute_reply.started":"2025-08-09T07:05:28.022644Z","shell.execute_reply":"2025-08-09T07:05:29.137584Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# **Load and Preprocess the dataset**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/f1-spam-detection/train.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:29.187779Z","iopub.execute_input":"2025-08-09T07:05:29.188199Z","iopub.status.idle":"2025-08-09T07:05:29.266137Z","shell.execute_reply.started":"2025-08-09T07:05:29.188176Z","shell.execute_reply":"2025-08-09T07:05:29.265398Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   message_id  num_links  num_words  has_offer  sender_score  all_caps  \\\n0           1          3         98          1      0.718607         0   \n1           2          0        170          0      0.698901         1   \n2           3          0         38          0      0.620466         0   \n3           4          0        116          0      0.701755         0   \n4           5          3         89          1      0.583621         1   \n\n   is_spam  \n0        0  \n1        0  \n2        0  \n3        0  \n4        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message_id</th>\n      <th>num_links</th>\n      <th>num_words</th>\n      <th>has_offer</th>\n      <th>sender_score</th>\n      <th>all_caps</th>\n      <th>is_spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>98</td>\n      <td>1</td>\n      <td>0.718607</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>170</td>\n      <td>0</td>\n      <td>0.698901</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>38</td>\n      <td>0</td>\n      <td>0.620466</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>116</td>\n      <td>0</td>\n      <td>0.701755</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>89</td>\n      <td>1</td>\n      <td>0.583621</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:30.253808Z","iopub.execute_input":"2025-08-09T07:05:30.254454Z","iopub.status.idle":"2025-08-09T07:05:30.279865Z","shell.execute_reply.started":"2025-08-09T07:05:30.254427Z","shell.execute_reply":"2025-08-09T07:05:30.278755Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 19100 entries, 0 to 19099\nData columns (total 7 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   message_id    19100 non-null  int64  \n 1   num_links     19100 non-null  int64  \n 2   num_words     19100 non-null  int64  \n 3   has_offer     19100 non-null  int64  \n 4   sender_score  19100 non-null  float64\n 5   all_caps      19100 non-null  int64  \n 6   is_spam       19100 non-null  int64  \ndtypes: float64(1), int64(6)\nmemory usage: 1.0 MB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Check for null values\ndf.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:30.706699Z","iopub.execute_input":"2025-08-09T07:05:30.707508Z","iopub.status.idle":"2025-08-09T07:05:30.715434Z","shell.execute_reply.started":"2025-08-09T07:05:30.707472Z","shell.execute_reply":"2025-08-09T07:05:30.714383Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"message_id      0\nnum_links       0\nnum_words       0\nhas_offer       0\nsender_score    0\nall_caps        0\nis_spam         0\ndtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Check for duplicates\ndf.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:31.105977Z","iopub.execute_input":"2025-08-09T07:05:31.106693Z","iopub.status.idle":"2025-08-09T07:05:31.118170Z","shell.execute_reply.started":"2025-08-09T07:05:31.106661Z","shell.execute_reply":"2025-08-09T07:05:31.117377Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df['is_spam'].value_counts() # Dataset is imbalanced","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:33.735823Z","iopub.execute_input":"2025-08-09T07:05:33.736098Z","iopub.status.idle":"2025-08-09T07:05:33.745249Z","shell.execute_reply.started":"2025-08-09T07:05:33.736078Z","shell.execute_reply":"2025-08-09T07:05:33.744127Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"is_spam\n0    17354\n1     1746\nName: count, dtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Drop unnecessary columns\ndf.drop(['message_id'], axis=1,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:34.132407Z","iopub.execute_input":"2025-08-09T07:05:34.132726Z","iopub.status.idle":"2025-08-09T07:05:34.140344Z","shell.execute_reply.started":"2025-08-09T07:05:34.132700Z","shell.execute_reply":"2025-08-09T07:05:34.139401Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Feature Engineering\ndf['links_per_word'] = df['num_links'] / (df['num_words'] + 1)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:34.529500Z","iopub.execute_input":"2025-08-09T07:05:34.530287Z","iopub.status.idle":"2025-08-09T07:05:34.558865Z","shell.execute_reply.started":"2025-08-09T07:05:34.530245Z","shell.execute_reply":"2025-08-09T07:05:34.558105Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   num_links  num_words  has_offer  sender_score  all_caps  is_spam  \\\n0          3         98          1      0.718607         0        0   \n1          0        170          0      0.698901         1        0   \n2          0         38          0      0.620466         0        0   \n3          0        116          0      0.701755         0        0   \n4          3         89          1      0.583621         1        1   \n\n   links_per_word  \n0        0.030303  \n1        0.000000  \n2        0.000000  \n3        0.000000  \n4        0.033333  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_links</th>\n      <th>num_words</th>\n      <th>has_offer</th>\n      <th>sender_score</th>\n      <th>all_caps</th>\n      <th>is_spam</th>\n      <th>links_per_word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>98</td>\n      <td>1</td>\n      <td>0.718607</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.030303</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>170</td>\n      <td>0</td>\n      <td>0.698901</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>38</td>\n      <td>0</td>\n      <td>0.620466</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>116</td>\n      <td>0</td>\n      <td>0.701755</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>89</td>\n      <td>1</td>\n      <td>0.583621</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.033333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:34.910597Z","iopub.execute_input":"2025-08-09T07:05:34.910892Z","iopub.status.idle":"2025-08-09T07:05:34.943263Z","shell.execute_reply.started":"2025-08-09T07:05:34.910872Z","shell.execute_reply":"2025-08-09T07:05:34.942424Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"          num_links     num_words     has_offer  sender_score      all_caps  \\\ncount  19100.000000  19100.000000  19100.000000  19100.000000  19100.000000   \nmean       1.498272    109.651780      0.303298      0.694174      0.097853   \nstd        1.221115     51.974463      0.459695      0.188285      0.297124   \nmin        0.000000     20.000000      0.000000      0.000000      0.000000   \n25%        1.000000     65.000000      0.000000      0.566990      0.000000   \n50%        1.000000    110.000000      0.000000      0.699204      0.000000   \n75%        2.000000    155.000000      1.000000      0.834200      0.000000   \nmax        9.000000    199.000000      1.000000      1.000000      1.000000   \n\n            is_spam  links_per_word  \ncount  19100.000000    19100.000000  \nmean       0.091414        0.018992  \nstd        0.288204        0.023753  \nmin        0.000000        0.000000  \n25%        0.000000        0.005435  \n50%        0.000000        0.012346  \n75%        0.000000        0.024390  \nmax        1.000000        0.318182  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_links</th>\n      <th>num_words</th>\n      <th>has_offer</th>\n      <th>sender_score</th>\n      <th>all_caps</th>\n      <th>is_spam</th>\n      <th>links_per_word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>19100.000000</td>\n      <td>19100.000000</td>\n      <td>19100.000000</td>\n      <td>19100.000000</td>\n      <td>19100.000000</td>\n      <td>19100.000000</td>\n      <td>19100.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.498272</td>\n      <td>109.651780</td>\n      <td>0.303298</td>\n      <td>0.694174</td>\n      <td>0.097853</td>\n      <td>0.091414</td>\n      <td>0.018992</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.221115</td>\n      <td>51.974463</td>\n      <td>0.459695</td>\n      <td>0.188285</td>\n      <td>0.297124</td>\n      <td>0.288204</td>\n      <td>0.023753</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>65.000000</td>\n      <td>0.000000</td>\n      <td>0.566990</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005435</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>110.000000</td>\n      <td>0.000000</td>\n      <td>0.699204</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012346</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n      <td>155.000000</td>\n      <td>1.000000</td>\n      <td>0.834200</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.024390</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>199.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.318182</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:37.179562Z","iopub.execute_input":"2025-08-09T07:05:37.179858Z","iopub.status.idle":"2025-08-09T07:05:37.199986Z","shell.execute_reply.started":"2025-08-09T07:05:37.179835Z","shell.execute_reply":"2025-08-09T07:05:37.199075Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                num_links  num_words  has_offer  sender_score  all_caps  \\\nnum_links        1.000000   0.003194  -0.004057     -0.002424  0.000682   \nnum_words        0.003194   1.000000  -0.005518      0.004276  0.001451   \nhas_offer       -0.004057  -0.005518   1.000000     -0.002169 -0.001098   \nsender_score    -0.002424   0.004276  -0.002169      1.000000  0.018184   \nall_caps         0.000682   0.001451  -0.001098      0.018184  1.000000   \nis_spam          0.322846   0.000849   0.368503     -0.088210  0.207979   \nlinks_per_word   0.657699  -0.488613  -0.006697     -0.007697 -0.002816   \n\n                 is_spam  links_per_word  \nnum_links       0.322846        0.657699  \nnum_words       0.000849       -0.488613  \nhas_offer       0.368503       -0.006697  \nsender_score   -0.088210       -0.007697  \nall_caps        0.207979       -0.002816  \nis_spam         1.000000        0.210271  \nlinks_per_word  0.210271        1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_links</th>\n      <th>num_words</th>\n      <th>has_offer</th>\n      <th>sender_score</th>\n      <th>all_caps</th>\n      <th>is_spam</th>\n      <th>links_per_word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>num_links</th>\n      <td>1.000000</td>\n      <td>0.003194</td>\n      <td>-0.004057</td>\n      <td>-0.002424</td>\n      <td>0.000682</td>\n      <td>0.322846</td>\n      <td>0.657699</td>\n    </tr>\n    <tr>\n      <th>num_words</th>\n      <td>0.003194</td>\n      <td>1.000000</td>\n      <td>-0.005518</td>\n      <td>0.004276</td>\n      <td>0.001451</td>\n      <td>0.000849</td>\n      <td>-0.488613</td>\n    </tr>\n    <tr>\n      <th>has_offer</th>\n      <td>-0.004057</td>\n      <td>-0.005518</td>\n      <td>1.000000</td>\n      <td>-0.002169</td>\n      <td>-0.001098</td>\n      <td>0.368503</td>\n      <td>-0.006697</td>\n    </tr>\n    <tr>\n      <th>sender_score</th>\n      <td>-0.002424</td>\n      <td>0.004276</td>\n      <td>-0.002169</td>\n      <td>1.000000</td>\n      <td>0.018184</td>\n      <td>-0.088210</td>\n      <td>-0.007697</td>\n    </tr>\n    <tr>\n      <th>all_caps</th>\n      <td>0.000682</td>\n      <td>0.001451</td>\n      <td>-0.001098</td>\n      <td>0.018184</td>\n      <td>1.000000</td>\n      <td>0.207979</td>\n      <td>-0.002816</td>\n    </tr>\n    <tr>\n      <th>is_spam</th>\n      <td>0.322846</td>\n      <td>0.000849</td>\n      <td>0.368503</td>\n      <td>-0.088210</td>\n      <td>0.207979</td>\n      <td>1.000000</td>\n      <td>0.210271</td>\n    </tr>\n    <tr>\n      <th>links_per_word</th>\n      <td>0.657699</td>\n      <td>-0.488613</td>\n      <td>-0.006697</td>\n      <td>-0.007697</td>\n      <td>-0.002816</td>\n      <td>0.210271</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"X = df.drop(['is_spam'], axis=1).values\ny = df['is_spam'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:37.548604Z","iopub.execute_input":"2025-08-09T07:05:37.548909Z","iopub.status.idle":"2025-08-09T07:05:37.556493Z","shell.execute_reply.started":"2025-08-09T07:05:37.548887Z","shell.execute_reply":"2025-08-09T07:05:37.555564Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:37.871567Z","iopub.execute_input":"2025-08-09T07:05:37.872214Z","iopub.status.idle":"2025-08-09T07:05:37.877889Z","shell.execute_reply.started":"2025-08-09T07:05:37.872183Z","shell.execute_reply":"2025-08-09T07:05:37.877074Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([[3.00000000e+00, 9.80000000e+01, 1.00000000e+00, 7.18607000e-01,\n        0.00000000e+00, 3.03030303e-02],\n       [0.00000000e+00, 1.70000000e+02, 0.00000000e+00, 6.98901226e-01,\n        1.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 3.80000000e+01, 0.00000000e+00, 6.20465534e-01,\n        0.00000000e+00, 0.00000000e+00],\n       ...,\n       [0.00000000e+00, 1.45000000e+02, 0.00000000e+00, 6.00568655e-01,\n        0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 1.78000000e+02, 0.00000000e+00, 6.75468409e-01,\n        0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 8.00000000e+01, 0.00000000e+00, 6.97732338e-01,\n        0.00000000e+00, 0.00000000e+00]])"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:39.627892Z","iopub.execute_input":"2025-08-09T07:05:39.628197Z","iopub.status.idle":"2025-08-09T07:05:39.634432Z","shell.execute_reply.started":"2025-08-09T07:05:39.628172Z","shell.execute_reply":"2025-08-09T07:05:39.633556Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, ..., 0, 0, 0])"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Stratified train-validation split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:40.005726Z","iopub.execute_input":"2025-08-09T07:05:40.006042Z","iopub.status.idle":"2025-08-09T07:05:40.020188Z","shell.execute_reply.started":"2025-08-09T07:05:40.006018Z","shell.execute_reply":"2025-08-09T07:05:40.019197Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Verify stratification\nprint(\"Training set class distribution:\", np.bincount(y_train))\nprint(\"Validation set class distribution:\", np.bincount(y_val))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:40.359062Z","iopub.execute_input":"2025-08-09T07:05:40.359404Z","iopub.status.idle":"2025-08-09T07:05:40.366056Z","shell.execute_reply.started":"2025-08-09T07:05:40.359377Z","shell.execute_reply":"2025-08-09T07:05:40.364918Z"}},"outputs":[{"name":"stdout","text":"Training set class distribution: [13883  1397]\nValidation set class distribution: [3471  349]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:40.904742Z","iopub.execute_input":"2025-08-09T07:05:40.905034Z","iopub.status.idle":"2025-08-09T07:05:40.918740Z","shell.execute_reply.started":"2025-08-09T07:05:40.905012Z","shell.execute_reply":"2025-08-09T07:05:40.917617Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# **Logistic Regression**","metadata":{}},{"cell_type":"code","source":"class LogisticRegression:\n    def __init__(self, learning_rate=0.01, max_iterations=1000, lambda_reg=0.1,\n                 reg_type='l2', class_weight=None, batch_size=32, shuffle=True):\n        # Hyperparameters\n        self.learning_rate = learning_rate\n        self.max_iterations = max_iterations\n        self.lambda_reg = lambda_reg\n        self.reg_type = reg_type.lower()\n        self.class_weight = class_weight  # None, 'balanced', or dict\n        self.batch_size = batch_size      # Mini-batch size\n        self.shuffle = shuffle            # Shuffle data each epoch\n\n        # Model parameters\n        self.weights = None\n        self.bias = None\n\n    def sigmoid(self, z):\n        \"\"\"Sigmoid activation with clipping to avoid overflow.\"\"\"\n        z = np.clip(z, -500, 500)\n        return 1 / (1 + np.exp(-z))\n\n    def log_loss(self, y_true, y_pred):\n        \"\"\"Binary cross-entropy loss with regularization.\"\"\"\n        epsilon = 1e-15\n        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Avoid log(0)\n        loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n\n        # Add regularization penalty\n        if self.reg_type == 'l1':\n            reg_term = self.lambda_reg * np.sum(np.abs(self.weights))\n        elif self.reg_type == 'l2':\n            reg_term = self.lambda_reg * np.sum(self.weights ** 2) / 2\n        else:\n            raise ValueError(\"reg_type must be 'l1' or 'l2'\")\n\n        return loss + reg_term\n\n    def _compute_sample_weights(self, y):\n        \"\"\"Convert class_weight into a weight for each sample.\"\"\"\n        if self.class_weight == 'balanced':\n            # Weight inversely proportional to class frequency\n            classes, counts = np.unique(y, return_counts=True)\n            total = len(y)\n            weight_dict = {cls: total / (2 * count) for cls, count in zip(classes, counts)}\n            return np.array([weight_dict[label] for label in y])\n\n        elif isinstance(self.class_weight, dict):\n            # Manual class weights\n            return np.array([self.class_weight[label] for label in y])\n\n        else:\n            # No weighting\n            return np.ones_like(y)\n\n    def fit(self, X, y):\n        \"\"\"Train the logistic regression model using mini-batch gradient descent.\"\"\"\n        n_samples, n_features = X.shape\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        sample_weights = self._compute_sample_weights(y)\n\n        for _ in range(self.max_iterations):\n            # Shuffle data each epoch if enabled\n            if self.shuffle:\n                indices = np.arange(n_samples)\n                np.random.shuffle(indices)\n                X = X[indices]\n                y = y[indices]\n                sample_weights = sample_weights[indices]\n\n            # Process each mini-batch\n            for start in range(0, n_samples, self.batch_size):\n                end = start + self.batch_size\n                X_batch = X[start:end]\n                y_batch = y[start:end]\n                sw_batch = sample_weights[start:end]\n\n                # Forward pass\n                linear_model = np.dot(X_batch, self.weights) + self.bias\n                y_pred = self.sigmoid(linear_model)\n\n                # Compute weighted error\n                error = y_pred - y_batch\n                weighted_error = error * sw_batch\n\n                # Regularization gradient\n                if self.reg_type == 'l1':\n                    reg_grad = self.lambda_reg * np.sign(self.weights)\n                elif self.reg_type == 'l2':\n                    reg_grad = self.lambda_reg * self.weights\n                else:\n                    raise ValueError(\"reg_type must be 'l1' or 'l2'\")\n\n                # Gradients\n                dw = (1 / len(X_batch)) * np.dot(X_batch.T, weighted_error) + (reg_grad / n_samples)\n                db = (1 / len(X_batch)) * np.sum(weighted_error)\n\n                # Parameter update\n                self.weights -= self.learning_rate * dw\n                self.bias -= self.learning_rate * db\n\n    def predict_proba(self, X):\n        \"\"\"Predict probabilities for input samples.\"\"\"\n        return self.sigmoid(np.dot(X, self.weights) + self.bias)\n\n    def predict(self, X, threshold=0.5):\n        \"\"\"Predict binary class labels based on a threshold.\"\"\"\n        return (self.predict_proba(X) >= threshold).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:46.369952Z","iopub.execute_input":"2025-08-09T07:05:46.370234Z","iopub.status.idle":"2025-08-09T07:05:46.386890Z","shell.execute_reply.started":"2025-08-09T07:05:46.370215Z","shell.execute_reply":"2025-08-09T07:05:46.385752Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def grid_search(X_train, y_train, X_val, y_val, param_grid):\n    best_log_loss = float('inf')\n    best_params = None\n    best_model = None\n\n    # Try every combination of parameters\n    for lr in param_grid['learning_rate']:\n        for lam in param_grid['lambda_reg']:\n            for max_iter in param_grid['max_iterations']:\n                for reg_type in param_grid['reg_type']:\n                    for class_weight in param_grid['class_weights']:\n                        for batch_size in param_grid['batch_size']:\n\n                            # Create model with given hyperparameters\n                            model = LogisticRegression(\n                                learning_rate=lr,\n                                max_iterations=max_iter,\n                                lambda_reg=lam,\n                                reg_type=reg_type,\n                                class_weight=class_weight,\n                                batch_size=batch_size\n                            )\n\n                            # Train model\n                            model.fit(X_train, y_train)\n\n                            # Evaluate on validation set\n                            y_pred_proba = model.predict_proba(X_val)\n                            log_loss_val = model.log_loss(y_val, y_pred_proba)\n\n                            # Print current combination results\n                            print(f\"LR: {lr}, Lambda: {lam}, MaxIter: {max_iter}, \"\n                                  f\"Reg: {reg_type}, Class Weight: {class_weight}, \"\n                                  f\"Batch: {batch_size}, LogLoss: {log_loss_val:.4f}\")\n\n                            # Track best model\n                            if log_loss_val < best_log_loss:\n                                best_log_loss = log_loss_val\n                                best_params = {\n                                    'learning_rate': lr,\n                                    'lambda_reg': lam,\n                                    'max_iterations': max_iter,\n                                    'reg_type': reg_type,\n                                    'class_weight': class_weight,\n                                    'batch_size': batch_size\n                                }\n                                best_model = model\n\n    return best_model, best_params, best_log_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:05:49.843082Z","iopub.execute_input":"2025-08-09T07:05:49.843452Z","iopub.status.idle":"2025-08-09T07:05:49.851655Z","shell.execute_reply.started":"2025-08-09T07:05:49.843424Z","shell.execute_reply":"2025-08-09T07:05:49.850387Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"param_grid = {\n    'learning_rate': [ 0.05, 0.01],\n    'lambda_reg': [ 0.0001, 0.001],\n    'max_iterations': [5000, 6000,7000],\n    'reg_type': ['L2','L1'],\n    'class_weights': [None],\n    'batch_size': [8, 16, 128]\n}\n\nbest_model, best_params, best_log_loss = grid_search(\n    X_train_scaled, y_train, X_val_scaled, y_val, param_grid\n)\n\nprint(\"\\n Best Parameters:\", best_params)\nprint(f\" Best Validation LogLoss: {best_log_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T07:06:01.323710Z","iopub.execute_input":"2025-08-09T07:06:01.324045Z","iopub.status.idle":"2025-08-09T11:10:00.875874Z","shell.execute_reply.started":"2025-08-09T07:06:01.324020Z","shell.execute_reply":"2025-08-09T11:10:00.874529Z"}},"outputs":[{"name":"stdout","text":"LR: 0.05, Lambda: 0.0001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1617\nLR: 0.05, Lambda: 0.0001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1626\nLR: 0.05, Lambda: 0.0001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1618\nLR: 0.05, Lambda: 0.0001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1612\nLR: 0.05, Lambda: 0.0001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1618\nLR: 0.05, Lambda: 0.0001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1619\nLR: 0.05, Lambda: 0.0001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1630\nLR: 0.05, Lambda: 0.0001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1627\nLR: 0.05, Lambda: 0.0001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1618\nLR: 0.05, Lambda: 0.0001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1619\nLR: 0.05, Lambda: 0.0001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1619\nLR: 0.05, Lambda: 0.0001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1620\nLR: 0.05, Lambda: 0.0001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1627\nLR: 0.05, Lambda: 0.0001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1614\nLR: 0.05, Lambda: 0.0001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1619\nLR: 0.05, Lambda: 0.0001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1625\nLR: 0.05, Lambda: 0.0001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1620\nLR: 0.05, Lambda: 0.0001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1619\nLR: 0.05, Lambda: 0.001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1652\nLR: 0.05, Lambda: 0.001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1651\nLR: 0.05, Lambda: 0.001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1654\nLR: 0.05, Lambda: 0.001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1697\nLR: 0.05, Lambda: 0.001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1668\nLR: 0.05, Lambda: 0.001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1666\nLR: 0.05, Lambda: 0.001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1669\nLR: 0.05, Lambda: 0.001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1657\nLR: 0.05, Lambda: 0.001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1654\nLR: 0.05, Lambda: 0.001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1668\nLR: 0.05, Lambda: 0.001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1668\nLR: 0.05, Lambda: 0.001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1667\nLR: 0.05, Lambda: 0.001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1661\nLR: 0.05, Lambda: 0.001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1653\nLR: 0.05, Lambda: 0.001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1661\nLR: 0.05, Lambda: 0.001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1662\nLR: 0.05, Lambda: 0.001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1666\nLR: 0.01, Lambda: 0.0001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1616\nLR: 0.01, Lambda: 0.0001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1619\nLR: 0.01, Lambda: 0.0001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1618\nLR: 0.01, Lambda: 0.0001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1619\nLR: 0.01, Lambda: 0.0001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1618\nLR: 0.01, Lambda: 0.0001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1619\nLR: 0.01, Lambda: 0.0001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1620\nLR: 0.01, Lambda: 0.0001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1619\nLR: 0.01, Lambda: 0.0001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1618\nLR: 0.01, Lambda: 0.0001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1618\nLR: 0.01, Lambda: 0.0001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1619\nLR: 0.01, Lambda: 0.0001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1619\nLR: 0.01, Lambda: 0.0001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1617\nLR: 0.01, Lambda: 0.0001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1617\nLR: 0.01, Lambda: 0.0001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1618\nLR: 0.01, Lambda: 0.0001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1622\nLR: 0.01, Lambda: 0.0001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1618\nLR: 0.01, Lambda: 0.0001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1619\nLR: 0.01, Lambda: 0.001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1655\nLR: 0.01, Lambda: 0.001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1653\nLR: 0.01, Lambda: 0.001, MaxIter: 5000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1654\nLR: 0.01, Lambda: 0.001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1666\nLR: 0.01, Lambda: 0.001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1666\nLR: 0.01, Lambda: 0.001, MaxIter: 5000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1666\nLR: 0.01, Lambda: 0.001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1652\nLR: 0.01, Lambda: 0.001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1656\nLR: 0.01, Lambda: 0.001, MaxIter: 6000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1654\nLR: 0.01, Lambda: 0.001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1665\nLR: 0.01, Lambda: 0.001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1666\nLR: 0.01, Lambda: 0.001, MaxIter: 6000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1666\nLR: 0.01, Lambda: 0.001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 8, LogLoss: 0.1653\nLR: 0.01, Lambda: 0.001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 16, LogLoss: 0.1654\nLR: 0.01, Lambda: 0.001, MaxIter: 7000, Reg: L2, Class Weight: None, Batch: 128, LogLoss: 0.1654\nLR: 0.01, Lambda: 0.001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 8, LogLoss: 0.1668\nLR: 0.01, Lambda: 0.001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 16, LogLoss: 0.1665\nLR: 0.01, Lambda: 0.001, MaxIter: 7000, Reg: L1, Class Weight: None, Batch: 128, LogLoss: 0.1666\n\n Best Parameters: {'learning_rate': 0.05, 'lambda_reg': 0.0001, 'max_iterations': 5000, 'reg_type': 'L1', 'class_weight': None, 'batch_size': 8}\n Best Validation LogLoss: 0.1612\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"best_model.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:15:19.234346Z","iopub.execute_input":"2025-08-09T11:15:19.234588Z","iopub.status.idle":"2025-08-09T11:20:35.388189Z","shell.execute_reply.started":"2025-08-09T11:15:19.234569Z","shell.execute_reply":"2025-08-09T11:20:35.387268Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"y_pred = best_model.predict_proba(X_val_scaled)\nprint(f'{best_model.log_loss(y_val, y_pred):.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:20:35.389109Z","iopub.execute_input":"2025-08-09T11:20:35.389474Z","iopub.status.idle":"2025-08-09T11:20:35.396189Z","shell.execute_reply.started":"2025-08-09T11:20:35.389447Z","shell.execute_reply":"2025-08-09T11:20:35.395418Z"}},"outputs":[{"name":"stdout","text":"0.1625\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/f1-spam-detection/test.csv\")\ntest.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:20:35.397149Z","iopub.execute_input":"2025-08-09T11:20:35.397509Z","iopub.status.idle":"2025-08-09T11:20:35.478681Z","shell.execute_reply.started":"2025-08-09T11:20:35.397486Z","shell.execute_reply":"2025-08-09T11:20:35.477868Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   message_id  num_links  num_words  has_offer  sender_score  all_caps\n0       20000          1         37          0      0.633935         0\n1       20001          0        174          0      0.577815         0\n2       20002          0        116          0      0.396098         0\n3       20003          0        112          0      0.646450         0\n4       20004          2         92          1      0.947398         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message_id</th>\n      <th>num_links</th>\n      <th>num_words</th>\n      <th>has_offer</th>\n      <th>sender_score</th>\n      <th>all_caps</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20000</td>\n      <td>1</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0.633935</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20001</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.577815</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20002</td>\n      <td>0</td>\n      <td>116</td>\n      <td>0</td>\n      <td>0.396098</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20003</td>\n      <td>0</td>\n      <td>112</td>\n      <td>0</td>\n      <td>0.646450</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20004</td>\n      <td>2</td>\n      <td>92</td>\n      <td>1</td>\n      <td>0.947398</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"features = test.drop(['message_id'],axis=1)\nids = test['message_id']\nids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:20:35.479590Z","iopub.execute_input":"2025-08-09T11:20:35.479900Z","iopub.status.idle":"2025-08-09T11:20:35.491086Z","shell.execute_reply.started":"2025-08-09T11:20:35.479877Z","shell.execute_reply":"2025-08-09T11:20:35.490354Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"0      20000\n1      20001\n2      20002\n3      20003\n4      20004\n       ...  \n895    20895\n896    20896\n897    20897\n898    20898\n899    20899\nName: message_id, Length: 900, dtype: int64"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"features['links_per_word'] = features['num_links'] / (features['num_words'] + 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:20:35.491971Z","iopub.execute_input":"2025-08-09T11:20:35.492374Z","iopub.status.idle":"2025-08-09T11:20:35.511610Z","shell.execute_reply.started":"2025-08-09T11:20:35.492250Z","shell.execute_reply":"2025-08-09T11:20:35.510588Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"features_scaled = scaler.transform(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:20:35.512748Z","iopub.execute_input":"2025-08-09T11:20:35.513063Z","iopub.status.idle":"2025-08-09T11:20:35.537350Z","shell.execute_reply.started":"2025-08-09T11:20:35.513035Z","shell.execute_reply":"2025-08-09T11:20:35.536211Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n  warnings.warn(\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"features_scaled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:20:35.538424Z","iopub.execute_input":"2025-08-09T11:20:35.538698Z","iopub.status.idle":"2025-08-09T11:20:35.558745Z","shell.execute_reply.started":"2025-08-09T11:20:35.538678Z","shell.execute_reply":"2025-08-09T11:20:35.557874Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([[-0.40651901, -1.40094477, -0.65955384, -0.32096753, -0.33078237,\n         0.31583616],\n       [-1.22512872,  1.23959789, -0.65955384, -0.62052284, -0.33078237,\n        -0.80432018],\n       [-1.22512872,  0.12170392, -0.65955384, -1.59048397, -0.33078237,\n        -0.80432018],\n       ...,\n       [-0.40651901,  0.73847301,  1.51617645,  0.26417161, -0.33078237,\n        -0.51864273],\n       [ 0.4120907 ,  1.23959789, -0.65955384, -0.60219107,  3.02313574,\n        -0.31785228],\n       [ 0.4120907 , -0.398695  , -0.65955384,  1.37254115, -0.33078237,\n         0.14158962]])"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"predictions = best_model.predict_proba(features_scaled)\npredictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:20:35.559638Z","iopub.execute_input":"2025-08-09T11:20:35.559883Z","iopub.status.idle":"2025-08-09T11:20:35.585850Z","shell.execute_reply.started":"2025-08-09T11:20:35.559863Z","shell.execute_reply":"2025-08-09T11:20:35.584913Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"array([1.02414786e-03, 3.31001284e-04, 5.58372148e-04, 2.54023052e-04,\n       7.77938623e-01, 3.36315336e-04, 6.81904675e-04, 2.18531232e-03,\n       1.52939914e-02, 5.63479023e-03, 1.64080193e-04, 4.40006902e-02,\n       3.80300913e-03, 3.01839795e-03, 1.50017223e-02, 3.60036291e-03,\n       4.58897524e-01, 2.87188350e-03, 2.30068745e-03, 9.64975872e-04,\n       1.07523005e-03, 1.92683552e-02, 5.10758763e-01, 1.77022793e-02,\n       6.53698974e-02, 1.98068453e-04, 3.46163247e-02, 1.55035540e-01,\n       5.38235613e-01, 5.94232442e-03, 2.29926059e-03, 2.49861530e-04,\n       1.35433640e-02, 4.28107614e-03, 8.18670288e-04, 7.73199089e-01,\n       1.91361205e-04, 5.27597022e-03, 1.94640913e-03, 1.70552367e-04,\n       2.06835115e-02, 1.07085965e-03, 8.34151170e-05, 2.33844229e-04,\n       9.45492217e-01, 7.79779402e-03, 8.36332699e-01, 2.87737893e-02,\n       2.76982262e-04, 6.86689774e-03, 8.21359401e-04, 1.68544776e-01,\n       1.60613685e-04, 2.66970522e-03, 1.66332222e-04, 5.28278533e-02,\n       3.63653653e-01, 3.56041913e-01, 6.64125654e-04, 3.66925739e-04,\n       1.11952317e-02, 4.73440568e-02, 1.90758707e-02, 7.52825037e-02,\n       2.29326784e-03, 5.77445653e-03, 4.53647089e-03, 7.98502811e-05,\n       1.61351185e-03, 7.25123778e-01, 3.60745682e-04, 3.25344338e-04,\n       2.23339099e-04, 8.92894116e-05, 1.53090888e-01, 9.90786663e-01,\n       4.76779827e-02, 2.42862251e-03, 4.86374585e-04, 1.36009443e-03,\n       3.83095493e-03, 1.06136668e-03, 1.17721926e-03, 2.78361230e-03,\n       2.88267703e-02, 7.81795723e-01, 5.87800590e-03, 6.32279972e-03,\n       4.64161081e-04, 4.61016728e-04, 2.77687677e-02, 3.46461186e-04,\n       1.89008343e-04, 1.67126697e-04, 7.11225777e-03, 2.70619539e-04,\n       4.08437699e-01, 2.15714544e-03, 1.48891081e-03, 7.52353245e-04,\n       2.96821611e-02, 1.42382906e-03, 7.84274617e-04, 1.38160202e-03,\n       8.00648896e-03, 7.54316477e-01, 2.33050155e-03, 2.72788147e-03,\n       3.71527370e-04, 9.99296028e-04, 1.84800829e-04, 2.23808826e-04,\n       3.26680714e-04, 7.07453986e-03, 1.69289051e-02, 2.36689598e-02,\n       2.16351738e-02, 3.84362541e-02, 1.50519779e-02, 3.46983626e-01,\n       9.56335387e-04, 5.01797196e-03, 1.67698250e-04, 8.03345573e-05,\n       1.16923991e-01, 1.47612366e-03, 6.58560370e-04, 3.12503747e-01,\n       1.37544052e-03, 4.67714189e-03, 1.67962671e-02, 5.11619657e-02,\n       7.87002548e-02, 1.01195314e-02, 2.76539060e-03, 1.25720486e-03,\n       8.49341237e-03, 1.48447478e-02, 7.30791489e-04, 5.46482458e-01,\n       1.15512974e-01, 7.27504055e-04, 4.78387770e-04, 2.77945951e-01,\n       8.36159640e-03, 1.02216224e-02, 1.62877898e-03, 1.45802324e-02,\n       8.29847642e-02, 2.49592474e-02, 1.49315778e-02, 1.69958669e-03,\n       1.00155486e-02, 8.13820060e-04, 4.94886280e-04, 1.73112909e-04,\n       3.08713325e-02, 1.40579211e-01, 7.39154915e-02, 5.78114085e-01,\n       1.46802525e-04, 8.18870807e-04, 9.39881667e-04, 1.19045512e-03,\n       1.11519444e-03, 7.39762127e-01, 1.01221179e-02, 3.75895231e-02,\n       1.32831055e-02, 2.03533529e-01, 3.29362421e-03, 8.94466910e-04,\n       2.64363231e-03, 2.65082638e-02, 5.81895073e-02, 2.03177647e-01,\n       2.65912350e-02, 6.53756753e-01, 5.12841793e-03, 1.32059670e-02,\n       4.32630198e-04, 1.22806782e-04, 5.40274336e-03, 5.10386481e-01,\n       5.41822820e-04, 1.41134021e-01, 2.49136884e-02, 1.50637444e-03,\n       2.77492284e-02, 2.32209634e-01, 1.06952129e-02, 6.86256822e-01,\n       3.69900148e-04, 2.43455760e-02, 7.55331294e-04, 1.13911033e-02,\n       7.19772850e-03, 1.52454696e-04, 4.92109788e-02, 8.27609770e-04,\n       2.21495824e-03, 2.44741289e-02, 2.33232900e-04, 9.35371595e-02,\n       2.59885704e-02, 9.75979179e-04, 7.68822536e-01, 4.00501925e-01,\n       3.08396899e-01, 1.40220408e-04, 7.53163827e-01, 1.03099729e-02,\n       1.52940878e-02, 5.00750928e-03, 9.22258547e-02, 2.69750218e-01,\n       1.32691201e-02, 2.33316326e-02, 1.40534306e-02, 3.35895973e-03,\n       4.27920479e-03, 6.28766746e-04, 6.80296819e-03, 2.12122572e-01,\n       4.83612187e-01, 4.35913620e-04, 3.99401503e-04, 5.25058621e-04,\n       7.89660856e-04, 7.50929426e-03, 1.17639785e-02, 6.07857906e-03,\n       5.08005799e-02, 5.81370872e-03, 2.13533105e-03, 2.76047612e-02,\n       4.05762671e-04, 2.81870006e-04, 2.35894592e-04, 1.75670264e-02,\n       6.16440785e-01, 1.88195248e-03, 9.26862340e-04, 1.39254586e-02,\n       5.96072347e-02, 2.20168227e-02, 1.87734781e-04, 1.93400793e-01,\n       9.35029643e-02, 9.99267002e-03, 6.24514772e-04, 9.67631884e-02,\n       2.95227949e-02, 1.42025694e-01, 1.88757576e-03, 3.36193292e-02,\n       3.01371931e-01, 1.09758998e-03, 7.26233014e-04, 1.10959605e-02,\n       8.42594164e-01, 3.98944597e-01, 2.66045178e-01, 4.38224129e-02,\n       2.02071709e-01, 5.89490163e-04, 8.97488951e-04, 1.51927283e-01,\n       4.11585851e-02, 2.74599288e-04, 1.55303811e-02, 2.58823246e-01,\n       2.51550923e-03, 2.59029068e-01, 1.35359459e-02, 1.48086027e-03,\n       6.17810693e-04, 2.07528922e-04, 1.05372217e-03, 6.32028311e-03,\n       6.71972811e-04, 1.28013502e-04, 8.08070646e-02, 8.31848964e-03,\n       1.65719350e-03, 3.10372770e-02, 4.37891540e-04, 5.39692706e-04,\n       1.67582275e-01, 2.58901716e-04, 1.64113102e-02, 3.24828585e-04,\n       4.11194770e-04, 2.32048485e-02, 3.30199428e-04, 1.01626727e-03,\n       7.05937643e-04, 1.05200362e-02, 3.44729673e-02, 1.32574928e-01,\n       4.44742240e-02, 3.73148212e-02, 1.89283449e-01, 6.73666842e-02,\n       1.98624897e-02, 6.02529999e-02, 1.77291712e-01, 1.94429953e-03,\n       2.23337354e-02, 1.67816423e-03, 1.83464223e-02, 3.58289447e-04,\n       1.49123647e-04, 2.38847363e-02, 1.84956455e-04, 1.17490256e-01,\n       1.14942299e-02, 2.49623296e-02, 3.18886411e-02, 4.81866981e-01,\n       1.00542983e-02, 2.13256097e-03, 1.10819319e-03, 9.74525599e-04,\n       3.73300189e-04, 9.49646722e-01, 2.08610261e-04, 9.99627515e-01,\n       7.06281419e-03, 1.91113112e-01, 3.26415153e-03, 1.29604199e-04,\n       2.39158573e-02, 8.78410920e-01, 5.45964664e-04, 7.09976927e-03,\n       7.76613516e-01, 3.04432793e-02, 4.19946639e-04, 3.13858591e-03,\n       1.97160315e-02, 4.10780272e-04, 5.74559466e-04, 4.76793224e-01,\n       1.97498778e-04, 6.82081512e-02, 2.90523110e-01, 1.56902216e-03,\n       3.73690180e-02, 4.51306652e-04, 2.94675806e-01, 3.62379190e-04,\n       1.02449159e-02, 3.14444550e-04, 2.67797635e-01, 1.70468635e-03,\n       1.13136788e-01, 7.63989398e-03, 7.82888618e-01, 8.10987317e-01,\n       8.90651398e-03, 2.46328438e-02, 3.27389560e-04, 5.42903416e-01,\n       9.25631620e-02, 6.01072049e-02, 2.39348173e-02, 4.92875738e-03,\n       2.17368117e-01, 2.32050943e-01, 4.66696830e-01, 1.85613371e-03,\n       3.21781560e-04, 1.15861922e-04, 1.77294206e-04, 7.88687689e-05,\n       1.73419941e-01, 3.77475468e-01, 5.61411942e-04, 3.56504670e-03,\n       2.59893693e-04, 4.48073093e-02, 1.46415117e-03, 1.06291899e-01,\n       1.29916512e-03, 2.20308339e-03, 4.44115592e-03, 2.34349451e-02,\n       4.82122640e-01, 4.31958209e-02, 1.22921963e-03, 1.67889035e-03,\n       1.09970654e-04, 3.34409724e-04, 2.65113625e-02, 1.82384621e-01,\n       1.01780010e-02, 8.98611143e-01, 3.55965235e-02, 6.76613942e-02,\n       2.86790221e-02, 5.17817814e-04, 7.25741383e-04, 1.56506504e-02,\n       1.16070461e-01, 8.09384863e-01, 7.37098346e-01, 1.94194386e-01,\n       1.51055924e-04, 1.19621443e-03, 2.10425992e-01, 1.95849567e-04,\n       4.40911568e-01, 3.14751430e-03, 7.91217538e-05, 1.57939141e-01,\n       6.03712546e-01, 1.88860764e-03, 4.20120882e-02, 1.76640660e-03,\n       1.55971822e-01, 2.02633897e-03, 5.01916640e-04, 3.01801758e-04,\n       1.08149282e-02, 1.52355959e-03, 2.11127146e-04, 5.24070530e-03,\n       2.72540427e-03, 5.18993540e-03, 8.76948884e-04, 7.73405026e-01,\n       4.33702692e-03, 1.11067191e-01, 1.11326378e-02, 3.56099846e-03,\n       2.44257608e-02, 2.04101532e-03, 2.06261766e-01, 5.55981536e-04,\n       1.34908921e-03, 2.31381316e-03, 6.94926342e-03, 1.80764026e-01,\n       4.83429802e-04, 3.88016049e-04, 1.90220229e-03, 2.19839287e-03,\n       1.32902506e-03, 8.28196886e-04, 1.26350287e-01, 9.80571532e-01,\n       5.89047182e-04, 2.53150914e-01, 5.58011636e-03, 5.24391941e-01,\n       8.88371186e-04, 4.99831617e-03, 1.71418137e-03, 1.53002871e-03,\n       5.88297275e-03, 4.34756258e-04, 1.99080307e-03, 4.80607088e-01,\n       2.13357410e-03, 2.72571823e-03, 9.83864621e-01, 6.95781233e-04,\n       6.70052994e-02, 3.99001857e-04, 1.46111560e-03, 7.41450806e-01,\n       2.81208399e-03, 2.98816153e-04, 3.17957473e-03, 5.01094931e-04,\n       9.39991336e-01, 2.84131128e-01, 4.10904144e-04, 1.97524933e-04,\n       6.33691650e-04, 6.35956502e-02, 8.51072554e-04, 1.51114401e-03,\n       8.62546913e-01, 2.23220184e-02, 1.10421696e-01, 3.39256785e-04,\n       1.55384610e-01, 3.20280187e-03, 7.23682267e-03, 1.08683865e-02,\n       1.61136084e-03, 1.67829814e-02, 2.09428325e-03, 2.09932431e-03,\n       2.54460755e-01, 7.62400497e-01, 3.19050401e-01, 2.07839534e-01,\n       4.15739363e-01, 5.65540498e-01, 2.51510592e-04, 4.46260986e-01,\n       1.20274602e-03, 2.24638126e-04, 2.54545728e-02, 1.48697010e-03,\n       1.27685569e-04, 8.79863844e-02, 6.34939001e-03, 6.77813272e-04,\n       9.39579773e-03, 2.69067392e-03, 8.37135901e-01, 6.66196280e-01,\n       1.12995799e-03, 4.64509454e-04, 4.50546450e-01, 7.65954775e-02,\n       4.32391164e-03, 7.63989688e-04, 4.82261125e-04, 3.07965596e-03,\n       6.76656596e-03, 5.57393612e-04, 2.83169969e-03, 1.26888170e-02,\n       3.61750315e-04, 1.16918328e-01, 8.51697152e-05, 1.14833734e-02,\n       3.98160177e-04, 9.21705124e-01, 2.84540322e-01, 2.29890649e-04,\n       3.38929137e-03, 1.14007153e-03, 2.48069527e-01, 5.78826358e-03,\n       8.35696248e-04, 4.12126963e-01, 1.12160372e-02, 3.23834105e-03,\n       1.06638657e-01, 1.20273842e-04, 2.26808611e-04, 3.93687472e-02,\n       5.40958880e-02, 7.19501785e-04, 2.99669671e-02, 8.54412640e-03,\n       9.30067300e-04, 6.31242490e-01, 2.98723899e-01, 4.91987175e-02,\n       1.98964179e-02, 1.45854082e-04, 6.42650024e-03, 2.24994163e-04,\n       7.46896013e-04, 1.21354847e-02, 9.37356931e-02, 9.40779839e-04,\n       3.81394763e-02, 9.39104139e-02, 7.18107465e-04, 1.79057867e-01,\n       1.27917248e-02, 1.80746944e-03, 3.40221239e-02, 1.92851123e-04,\n       1.78141570e-01, 5.34332623e-02, 6.80969138e-04, 8.89105794e-03,\n       9.34447356e-04, 2.13342879e-04, 4.31253779e-04, 4.48563548e-03,\n       3.73887514e-03, 2.08021645e-01, 2.31864672e-04, 2.80201419e-02,\n       3.48582798e-01, 8.28162153e-05, 4.10199044e-02, 1.35775262e-03,\n       7.07490361e-04, 3.99487423e-02, 4.34384490e-01, 6.12102704e-03,\n       5.71792257e-01, 1.55765004e-01, 1.47442885e-02, 1.49036468e-03,\n       1.70812767e-02, 2.08332049e-04, 3.05213966e-03, 7.18521195e-04,\n       2.83095533e-03, 4.51113375e-04, 1.21733409e-02, 2.47232181e-04,\n       4.84129908e-02, 1.78520670e-01, 2.42607467e-03, 1.65758220e-03,\n       7.49296969e-04, 1.58048321e-03, 1.01376548e-04, 4.07788872e-04,\n       9.72624348e-04, 4.40073761e-02, 4.79667227e-04, 2.34189371e-02,\n       1.04708263e-02, 8.50397065e-03, 6.08253001e-01, 5.71489927e-01,\n       2.54369995e-03, 6.37693727e-04, 3.41739132e-04, 8.18886279e-02,\n       5.65615879e-03, 5.07813591e-03, 3.44326502e-03, 7.80911405e-03,\n       7.09206300e-04, 1.36379900e-02, 5.57479274e-01, 3.17222360e-01,\n       7.13725046e-04, 6.10916257e-01, 1.76535169e-03, 1.83013190e-01,\n       1.87259531e-02, 8.20715872e-03, 1.20294634e-03, 7.97463409e-03,\n       4.89487548e-01, 4.76865763e-01, 1.50008382e-04, 3.68904941e-03,\n       1.54875454e-04, 1.86403094e-01, 8.61166765e-02, 5.39020837e-02,\n       3.60015778e-04, 6.12722450e-04, 2.61152282e-03, 5.37699624e-04,\n       6.49821871e-04, 1.18985883e-03, 4.34778335e-04, 4.84788403e-02,\n       5.01670148e-02, 3.69441488e-04, 2.34626704e-01, 8.33837898e-04,\n       4.07846385e-04, 3.89612578e-04, 5.60237564e-03, 1.08204752e-02,\n       1.10960387e-03, 8.02618181e-02, 3.83766314e-03, 1.84054954e-04,\n       4.68050694e-04, 1.55232434e-02, 7.47487415e-04, 1.54496441e-02,\n       1.44381298e-03, 1.23824273e-01, 2.70349247e-02, 5.51696310e-01,\n       1.82286031e-03, 1.18603378e-03, 1.91222364e-03, 6.56784108e-01,\n       1.27213312e-02, 1.60568939e-01, 1.79467316e-02, 3.56602856e-04,\n       1.43846686e-04, 2.89129555e-01, 1.00194729e-03, 6.76498969e-01,\n       6.72403615e-02, 1.47494180e-03, 2.57694495e-02, 5.30096189e-04,\n       4.07800349e-04, 1.03554145e-03, 2.65527842e-01, 3.71107121e-04,\n       1.37140465e-04, 6.41941500e-03, 1.13432957e-04, 2.14353280e-01,\n       1.39035922e-01, 2.02966919e-04, 1.52642519e-04, 1.01382798e-01,\n       9.83584171e-02, 4.02865143e-03, 5.51718078e-03, 1.83051490e-03,\n       2.01152720e-03, 2.81832303e-01, 6.05666541e-04, 3.04639612e-01,\n       2.43541524e-01, 2.55252011e-03, 9.10974111e-03, 8.99943839e-05,\n       9.82425998e-05, 2.41714954e-01, 5.11264889e-04, 4.73431944e-04,\n       4.00915077e-04, 1.00735530e-03, 6.11845036e-04, 1.58411575e-04,\n       4.58041502e-02, 1.28469163e-02, 5.15647957e-03, 1.99795928e-03,\n       1.90130913e-02, 1.80275956e-03, 6.93828473e-04, 1.09161167e-01,\n       7.10372549e-01, 3.03967114e-04, 2.39755118e-04, 1.74751577e-03,\n       1.14939725e-04, 9.53662839e-03, 3.87234077e-03, 2.70558375e-03,\n       8.97912280e-05, 4.15756903e-01, 1.09731159e-03, 6.75546720e-01,\n       3.64108912e-01, 1.69407817e-03, 9.15222376e-04, 1.75620849e-03,\n       1.71642133e-02, 4.82629017e-03, 7.65848097e-04, 6.08460184e-03,\n       1.44420171e-03, 1.58612967e-04, 1.14683751e-01, 1.84757317e-01,\n       9.31032126e-03, 1.63598425e-03, 9.61568114e-04, 1.66551847e-03,\n       1.63429008e-04, 8.15943262e-01, 6.47282954e-02, 3.54576973e-04,\n       3.82976691e-03, 2.50912469e-01, 7.30602690e-02, 1.16320734e-03,\n       9.14187442e-03, 6.00433410e-02, 5.78289414e-03, 4.31057244e-03,\n       1.51913654e-01, 2.52008494e-01, 5.64505555e-02, 1.21479334e-01,\n       9.55204527e-01, 1.13307118e-02, 1.44081962e-04, 1.15558568e-01,\n       1.75917953e-03, 9.09519290e-05, 9.54040151e-03, 3.93529173e-01,\n       1.27854948e-02, 2.57150788e-04, 1.05645797e-03, 3.01696467e-03,\n       1.04071284e-04, 1.42161529e-01, 9.04171151e-04, 1.84701646e-01,\n       9.83321249e-01, 7.62598230e-03, 5.60237564e-03, 9.67222968e-01,\n       2.34233568e-04, 5.99644089e-03, 7.91242964e-01, 6.36175494e-04,\n       1.20845994e-03, 1.94959964e-01, 6.55015096e-03, 2.94025471e-01,\n       5.46530805e-03, 3.06876937e-02, 1.02033790e-03, 1.87739831e-03,\n       7.48655571e-03, 9.01339757e-04, 5.91401331e-03, 9.39122743e-04,\n       2.33529935e-01, 6.15937670e-01, 7.36254413e-04, 2.47102130e-02,\n       2.88402553e-01, 7.11563453e-01, 3.97152397e-04, 2.97561106e-03,\n       2.99018188e-02, 1.06367450e-02, 6.99762661e-04, 1.63611221e-03,\n       3.02920982e-03, 8.04632972e-05, 3.52281926e-02, 2.82654986e-02,\n       6.95356970e-04, 2.82260493e-02, 2.07664526e-03, 1.30958283e-02,\n       6.97697321e-04, 2.98882217e-04, 1.02250329e-01, 2.74268093e-03,\n       4.54903487e-03, 9.51630041e-02, 1.75978138e-03, 1.74193213e-03,\n       3.87814592e-01, 5.42465117e-01, 1.37986697e-03, 1.33310979e-02,\n       1.47945468e-03, 1.66401648e-04, 4.61375762e-01, 5.51825087e-03,\n       3.55695733e-04, 2.81783848e-04, 8.98619051e-04, 7.84548347e-04,\n       3.56267538e-04, 9.51936368e-03, 1.17961092e-03, 1.53679978e-04,\n       5.88447141e-04, 1.32839462e-03, 5.99733932e-04, 1.68737506e-02,\n       7.58263563e-04, 4.82628778e-04, 4.38597977e-04, 5.93976327e-03,\n       1.87679030e-03, 3.56000351e-04, 2.33005112e-02, 3.81815902e-02,\n       1.67476507e-02, 6.71808821e-02, 9.80984530e-02, 8.21078653e-04,\n       1.68028514e-02, 5.23294570e-01, 1.80299525e-03, 3.58016272e-03,\n       6.72128430e-04, 4.57460982e-01, 4.55805233e-02, 5.79008206e-04,\n       4.76872478e-01, 3.55377013e-02, 1.15248203e-03, 6.71702197e-03,\n       3.86649472e-02, 1.05527951e-03, 6.86868427e-04, 1.65460022e-03,\n       8.50378410e-04, 1.57841925e-03, 4.58649401e-01, 2.31686980e-02,\n       1.00667740e-03, 8.32329893e-03, 7.78190423e-04, 1.80014047e-01,\n       1.42691544e-03, 5.35685349e-02, 1.42057006e-01, 1.62708201e-03])"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'message_id': ids,\n    'Calories': predictions\n})\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:20:35.588562Z","iopub.execute_input":"2025-08-09T11:20:35.588834Z","iopub.status.idle":"2025-08-09T11:20:35.612808Z","shell.execute_reply.started":"2025-08-09T11:20:35.588813Z","shell.execute_reply":"2025-08-09T11:20:35.612015Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"   message_id  Calories\n0       20000  0.001024\n1       20001  0.000331\n2       20002  0.000558\n3       20003  0.000254\n4       20004  0.777939","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message_id</th>\n      <th>Calories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20000</td>\n      <td>0.001024</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20001</td>\n      <td>0.000331</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20002</td>\n      <td>0.000558</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20003</td>\n      <td>0.000254</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20004</td>\n      <td>0.777939</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T11:21:48.092971Z","iopub.execute_input":"2025-08-09T11:21:48.093305Z","iopub.status.idle":"2025-08-09T11:21:48.108625Z","shell.execute_reply.started":"2025-08-09T11:21:48.093273Z","shell.execute_reply":"2025-08-09T11:21:48.107641Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}